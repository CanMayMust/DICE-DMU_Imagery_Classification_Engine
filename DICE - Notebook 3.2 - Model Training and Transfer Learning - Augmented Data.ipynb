{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DICE - Notebook 3.2 - Model Training and Transfer Learning - Augmented Data\n",
    "\n",
    "<br/>\n",
    "\n",
    "```\n",
    "*************************************************************************\n",
    "**\n",
    "** 2017 Mai 23\n",
    "**\n",
    "** In place of a legal notice, here is a blessing:\n",
    "**\n",
    "**    May you do good and not evil.\n",
    "**    May you find forgiveness for yourself and forgive others.\n",
    "**    May you share freely, never taking more than you give.\n",
    "**\n",
    "*************************************************************************\n",
    "```\n",
    "\n",
    "<table style=\"width:100%; font-size:14px; margin: 20px 0;\">\n",
    "    <tr>\n",
    "        <td style=\"text-align:center\">\n",
    "            <b>Contact: </b><a href=\"mailto:contact@jonathandekhtiar.eu\" target=\"_blank\">contact@jonathandekhtiar.eu</a>\n",
    "        </td>\n",
    "        <td style=\"text-align:center\">\n",
    "            <b>Twitter: </b><a href=\"https://twitter.com/born2data\" target=\"_blank\">@born2data</a>\n",
    "        </td>\n",
    "        <td style=\"text-align:center\">\n",
    "            <b>Tech. Blog: </b><a href=\"http://www.born2data.com/\" target=\"_blank\">born2data.com</a>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:center\">\n",
    "            <b>Personal Website: </b><a href=\"http://www.jonathandekhtiar.eu\" target=\"_blank\">jonathandekhtiar.eu</a>\n",
    "        </td>\n",
    "        <td style=\"text-align:center\">\n",
    "            <b>RSS Feed: </b><a href=\"https://www.feedcrunch.io/@dataradar/\" target=\"_blank\">FeedCrunch.io</a>\n",
    "        </td>\n",
    "        <td style=\"text-align:center\">\n",
    "            <b>LinkedIn: </b><a href=\"https://fr.linkedin.com/in/jonathandekhtiar\" target=\"_blank\">JonathanDEKHTIAR</a>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "## Objectives\n",
    "\n",
    "This notebook aims to perform the actual transfer learning from the [ImageNet](http://www.image-net.org/) dataset to our custom dataset. For this we will load the model previously trained and retrain the last layers in order to obtain predictions on new classes.\n",
    "\n",
    "A wide variety of models has been trained and made available by the Google Team: https://github.com/tensorflow/models/tree/master/slim\n",
    "\n",
    "We will use in this Notebook, one of the most famous Deep Learning Model: GoogLeNet (aka. Inception-V1) developed by Christian Szegedy and published on ArXiv: https://arxiv.org/abs/1409.4842\n",
    "\n",
    "This notebook will use [Tensorflow-Slim](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim) to ease the understanding and reduce the code complexity.\n",
    "\n",
    "Download Inception-V1 Model: http://download.tensorflow.org/models/inception_v1_2016_08_28.tar.gz\n",
    "\n",
    "---\n",
    "\n",
    "As reminder before starting, the data have already been preprocessed (resized, augmented, etc.) in the first Notebook: **[DICE - Notebook 1 - Dataset Augmentation](https://github.com/DEKHTIARJonathan/DICE-DMU_Imagery_Classification_Engine/blob/master/DICE%20-%20Notebook%201%20-%20Dataset%20Augmentation.ipynb)**\n",
    "\n",
    "The preprocessed data all have been saved as **JPEG images** and thus we will only focus on these data.\n",
    "\n",
    "## 1. Notebook Initialisation\n",
    "\n",
    "### 1.1. Load the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys, time, math\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.framework.python.ops.variables import get_or_create_global_step\n",
    "from tensorflow.python.platform import tf_logging as logging\n",
    "\n",
    "slim = tf.contrib.slim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1.2 Initialise global variables and application Flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flags = tf.app.flags\n",
    "\n",
    "#State your dataset directory\n",
    "flags.DEFINE_string('dataset_dir', 'data_prepared', 'String: Your dataset directory')\n",
    "\n",
    "#Output filename for the naming the TFRecord file\n",
    "flags.DEFINE_string('output_dir', 'output/augmented', 'String: The output directory where model-checkpoints will be saved')\n",
    "\n",
    "#Output filename for the naming the TFRecord file\n",
    "flags.DEFINE_string('inception_dir', 'inception_files', 'String: The output directory where model-checkpoints will be saved')\n",
    "\n",
    "#Output filename for the naming the TFRecord file\n",
    "flags.DEFINE_string('labels_dir', 'data_prepared', 'String: The output directory where model-checkpoints will be saved')\n",
    "\n",
    "#Output filename for the naming the TFRecord file\n",
    "flags.DEFINE_string('tf_record_start_name', 'dmunet_augmented_dataset_', 'String: The output filename to name your TFRecord file')\n",
    "\n",
    "#State the number of epochs to train\n",
    "flags.DEFINE_integer('training_epochs', 5, 'Int: Number of shards to split the TFRecord files into')\n",
    "\n",
    "#State your batch size => Choose the highest value which doesn't give you a memory error.\n",
    "flags.DEFINE_integer('batch_size', 85, 'Int: Number of shards to split the TFRecord files into')\n",
    "\n",
    "#Learning rate information and configuration (Up to you to experiment)\n",
    "flags.DEFINE_float('initial_learning_rate', 1e-4, 'Float: The proportion of examples in the dataset to be used for validation')\n",
    "\n",
    "flags.DEFINE_float('learning_rate_decay_factor', 0.8, 'Float: The proportion of examples')\n",
    "\n",
    "flags.DEFINE_integer('num_epochs_before_decay', 1, 'Int: Number of shards to split the TFRecord files into')\n",
    "\n",
    "# Choose between \"tf.train.SaverDef.V2\" and \"tf.train.SaverDef.V1\". The V1 version is deprecated since Tensorflow r1.0.0\n",
    "flags.DEFINE_integer('tf_saver', tf.train.SaverDef.V1, 'Int: Number of shards to split the TFRecord files into')\n",
    "\n",
    "#Set the verbosity to INFO level => highest to lowest logging level: DEBUG > INFO > WARN > ERROR > FATAL  \n",
    "flags.DEFINE_integer('tf_logging_level', tf.logging.INFO, 'Int: Number of shards to split the TFRecord files into')\n",
    "\n",
    "#Output filename for the naming the TFRecord file\n",
    "flags.DEFINE_string('checkpoint_basename', 'dmunet_augmented_data.ckpt', 'String: The output filename to name your TFRecord file')\n",
    "\n",
    "FLAGS = flags.FLAGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1.3 Complementary imports from the inception directory set by the flags above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.path.append(FLAGS.inception_dir)\n",
    "\n",
    "from preprocessing      import inception_preprocessing\n",
    "from nets.inception_v1  import inception_v1, inception_v1_arg_scope\n",
    "from datasets           import dataset_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Environment Check and Model Downloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ================ Placeholders Definition ================\n",
    "\n",
    "training_step = tf.placeholder(tf.bool)\n",
    "\n",
    "# ================ Additional Derived Variable ================\n",
    "\n",
    "checkpoint_dir  = os.path.join(FLAGS.inception_dir, \"models\")\n",
    "checkpoint_file = os.path.join(checkpoint_dir, \"inception_v1.ckpt\")\n",
    "labels_file     = os.path.join(FLAGS.labels_dir, \"labels.txt\")\n",
    "\n",
    "image_size      = inception_v1.default_image_size # 224 (width and height in pixels)\n",
    "\n",
    "#Create the file pattern of your TFRecord files so that it could be recognized later on\n",
    "file_pattern    = FLAGS.tf_record_start_name + '%s_*.tfrecord'\n",
    "\n",
    "tf.logging.set_verbosity(FLAGS.tf_logging_level) \n",
    "\n",
    "#Create a dictionary that will help people understand your dataset better. This is required by the Dataset class later.\n",
    "\n",
    "items_to_descriptions = {\n",
    "    'image': 'A 3-channel RGB coloured flower image that is either tulips, sunflowers, roses, dandelion, or daisy.',\n",
    "    'label': 'A label that is as such -- 0:daisy, 1:dandelion, 2:roses, 3:sunflowers, 4:tulips'\n",
    "}\n",
    "\n",
    "# =================== Environment Checking ====================\n",
    "\n",
    "#Create the log directory here. Must be done here otherwise import will activate this unneededly.\n",
    "if not os.path.exists(FLAGS.output_dir):\n",
    "    os.mkdir(FLAGS.output_dir)\n",
    "    \n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "    \n",
    "if not os.path.isfile(checkpoint_file):\n",
    "    # We download first the TARGZ archive, if necessary, and then extract it.\n",
    "    \n",
    "    targz = \"inception_v1_2016_08_28.tar.gz\"\n",
    "    url = \"http://download.tensorflow.org/models/\" + targz\n",
    "    \n",
    "    tarfilepath = os.path.join(checkpoint_dir, targz)\n",
    "    \n",
    "    if os.path.isfile(tarfilepath):\n",
    "        import tarfile\n",
    "        tarfile.open(tarfilepath, 'r:gz').extractall(checkpoint_dir)\n",
    "    else:\n",
    "        dataset_utils.download_and_uncompress_tarball(url, checkpoint_dir)\n",
    "        \n",
    "    # Get rid of tarfile source (the checkpoint itself will remain)\n",
    "    os.unlink(tarfilepath)\n",
    "\n",
    "\n",
    "if not os.path.isfile(labels_file):\n",
    "    raise Exception(\"The Label File does not exists\")\n",
    "else:\n",
    "    #State the labels file and read it   \n",
    "    labels = open(labels_file, 'r')\n",
    "    \n",
    "    #Create a dictionary to refer each label to their string name\n",
    "    \n",
    "    labels_to_name = dict()\n",
    "    \n",
    "    for line in labels:\n",
    "        label, string_name = line.split(':')\n",
    "        string_name = string_name[:-1] #Remove newline\n",
    "        labels_to_name[int(label)] = string_name\n",
    "\n",
    "    #State the number of classes to predict\n",
    "    num_classes = len(labels_to_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training and Validation Datasets Loading\n",
    "\n",
    "### 3.1. Create a function that loads TFRecords Files and return a Dataset Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#============== DATASET LOADING ======================\n",
    "# We now create a function that creates a Dataset class which will give us many TFRecord files \n",
    "#to feed in the examples into a queue in parallel.\n",
    "\n",
    "def get_split(split_name, dataset_dir, file_pattern=file_pattern):\n",
    "    '''\n",
    "    Obtains the split - training or validation - to create a Dataset class for feeding the examples into a queue later on. This function will\n",
    "    set up the decoder and dataset information all into one Dataset class so that you can avoid the brute work later on.\n",
    "    Your file_pattern is very important in locating the files later. \n",
    "\n",
    "    INPUTS:\n",
    "    - split_name(str): 'train' or 'validation'. Used to get the correct data split of tfrecord files\n",
    "    - dataset_dir(str): the dataset directory where the tfrecord files are located\n",
    "    - file_pattern(str): the file name structure of the tfrecord files in order to get the correct data\n",
    "\n",
    "    OUTPUTS:\n",
    "    - dataset (Dataset): A Dataset class object where we can read its various components for easier batch creation later.\n",
    "    '''\n",
    "\n",
    "    #First check whether the split_name is train or validation\n",
    "    if split_name not in ['train', 'validation']: \n",
    "        err = 'The split_name %s is not recognized. Please input either train or validation as the split_name' % (split_name)\n",
    "        raise ValueError(err)\n",
    "    \n",
    "    file_pattern_for_counting = file_pattern % (split_name)\n",
    "    \n",
    "    #Count the total number of examples in all of these shard    \n",
    "    tfrecords_to_count = [\n",
    "        os.path.join(dataset_dir, file) \n",
    "        for file in os.listdir(dataset_dir) \n",
    "        if file.startswith(file_pattern_for_counting[:-10]) # We remove the 10 last chars: *.tfrecord   \n",
    "    ]\n",
    "    \n",
    "    num_samples = 0\n",
    "    \n",
    "    for tfrecord_file in tfrecords_to_count:\n",
    "        for record in tf.python_io.tf_record_iterator(tfrecord_file):\n",
    "            num_samples += 1\n",
    "\n",
    "    #Create a reader, which must be a TFRecord reader in this case\n",
    "    reader = tf.TFRecordReader\n",
    "\n",
    "    #Create the keys_to_features dictionary for the decoder\n",
    "    keys_to_features = {\n",
    "      'image/encoded': tf.FixedLenFeature((), tf.string, default_value=''),\n",
    "      'image/format': tf.FixedLenFeature((), tf.string, default_value='jpg'),\n",
    "      'image/class/label': tf.FixedLenFeature([], tf.int64, default_value=tf.zeros([], dtype=tf.int64)),\n",
    "    }\n",
    "\n",
    "    #Create the items_to_handlers dictionary for the decoder.\n",
    "    items_to_handlers = {\n",
    "        'image': slim.tfexample_decoder.Image(),\n",
    "        'label': slim.tfexample_decoder.Tensor('image/class/label'),\n",
    "    }\n",
    "\n",
    "    #Start to create the decoder\n",
    "    decoder = slim.tfexample_decoder.TFExampleDecoder(keys_to_features, items_to_handlers)\n",
    "\n",
    "    #Create the labels_to_name file\n",
    "    labels_to_name_dict = labels_to_name\n",
    "    \n",
    "    #Create the full path for a general file_pattern to locate the tfrecord_files\n",
    "    file_pattern_path = os.path.join(dataset_dir, file_pattern_for_counting)\n",
    "\n",
    "    #Actually create the dataset\n",
    "    dataset = slim.dataset.Dataset(\n",
    "        data_sources = file_pattern_path,\n",
    "        decoder = decoder,\n",
    "        reader = reader,\n",
    "        num_readers = 4,\n",
    "        num_samples = num_samples,\n",
    "        num_classes = num_classes,\n",
    "        labels_to_name = labels_to_name_dict,\n",
    "        items_to_descriptions = items_to_descriptions)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Create a function that return a batch of data for training or validation step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_batch(dataset, batch_size, height=image_size, width=image_size, is_training=True):\n",
    "    '''\n",
    "    Loads a batch for training.\n",
    "\n",
    "    INPUTS:\n",
    "    - dataset(Dataset): a Dataset class object that is created from the get_split function\n",
    "    - batch_size(int): determines how big of a batch to train\n",
    "    - height(int): the height of the image to resize to during preprocessing\n",
    "    - width(int): the width of the image to resize to during preprocessing\n",
    "    - is_training(bool): to determine whether to perform a training or evaluation preprocessing\n",
    "\n",
    "    OUTPUTS:\n",
    "    - images(Tensor): a Tensor of the shape (batch_size, height, width, channels) that contain one batch of images\n",
    "    - labels(Tensor): the batch's labels with the shape (batch_size,) (requires one_hot_encoding).\n",
    "\n",
    "    '''\n",
    "    #First create the data_provider object\n",
    "    data_provider = slim.dataset_data_provider.DatasetDataProvider(\n",
    "        dataset,\n",
    "        common_queue_capacity = 24 + 3 * batch_size,\n",
    "        common_queue_min = 24)\n",
    "\n",
    "    #Obtain the raw image using the get method\n",
    "    raw_image, label = data_provider.get(['image', 'label'])\n",
    "\n",
    "    #Perform the correct preprocessing for this image depending if it is training or evaluating\n",
    "    image = inception_preprocessing.preprocess_image(raw_image, height, width, is_training)\n",
    "\n",
    "    #As for the raw images, we just do a simple reshape to batch it up\n",
    "    raw_image = tf.expand_dims(raw_image, 0)\n",
    "    raw_image = tf.image.resize_nearest_neighbor(raw_image, [height, width])\n",
    "    raw_image = tf.squeeze(raw_image)\n",
    "\n",
    "    #Batch up the image by enqueing the tensors internally in a FIFO queue and dequeueing many elements with tf.train.batch.\n",
    "    images, raw_images, labels = tf.train.batch(\n",
    "        [image, raw_image, label],\n",
    "        batch_size = batch_size,\n",
    "        num_threads = 4,\n",
    "        capacity = 4 * batch_size,\n",
    "        allow_smaller_final_batch = True)\n",
    "\n",
    "    return images, raw_images, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Loading training and validation datasets and defining associated data batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_dataset = get_split('train', FLAGS.dataset_dir, file_pattern=file_pattern)\n",
    "training_batch = load_batch(training_dataset, batch_size=FLAGS.batch_size)\n",
    "\n",
    "validation_dataset = get_split('validation', FLAGS.dataset_dir, file_pattern=file_pattern)\n",
    "validation_batch = load_batch(training_dataset, batch_size=FLAGS.batch_size, is_training=False)\n",
    "\n",
    "images, _, labels = tf.cond(\n",
    "                        training_step,\n",
    "                        lambda: training_batch,\n",
    "                        lambda: validation_batch\n",
    "                    )\n",
    "\n",
    "num_training_steps_per_epoch = math.ceil(training_dataset.num_samples / FLAGS.batch_size)\n",
    "num_validation_steps_per_epoch = math.ceil(validation_dataset.num_samples / FLAGS.batch_size)\n",
    "\n",
    "#Know the number steps to take before decaying the learning rate and batches per epoch\n",
    "training_decay_steps = FLAGS.num_epochs_before_decay * num_training_steps_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create the model inference\n",
    "with slim.arg_scope(inception_v1_arg_scope()):\n",
    "    logits, end_points = inception_v1(images, num_classes = training_dataset.num_classes, is_training = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define the scopes that you want to exclude for restoration\n",
    "exclude              = [\"InceptionV1/Logits\", \"InceptionV1/AuxLogits\"]\n",
    "variables_to_restore = slim.get_variables_to_restore(exclude = exclude)\n",
    "variables_to_save    = slim.get_variables_to_restore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Perform one-hot-encoding of the labels (Try one-hot-encoding within the load_batch function!)\n",
    "one_hot_labels = slim.one_hot_encoding(labels, training_dataset.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Performs the equivalent to tf.nn.sparse_softmax_cross_entropy_with_logits but enhanced with checks\n",
    "loss = tf.losses.softmax_cross_entropy(onehot_labels = one_hot_labels, logits = logits)\n",
    "total_loss = tf.losses.get_total_loss()    #obtain the regularization losses as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create the global step for monitoring the learning_rate and training.\n",
    "global_step = get_or_create_global_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define your exponentially decaying learning rate\n",
    "lr = tf.train.exponential_decay(\n",
    "    learning_rate = FLAGS.initial_learning_rate,\n",
    "    global_step = global_step,\n",
    "    decay_steps = training_decay_steps,\n",
    "    decay_rate = FLAGS.learning_rate_decay_factor,\n",
    "    staircase = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now we can define the optimizer that takes on the learning rate\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create the train_op.\n",
    "train_op = slim.learning.create_train_op(total_loss, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#State the metrics that you want to predict. We get a predictions that is not one_hot_encoded.\n",
    "with tf.name_scope('metrics'):\n",
    "    probabilities              = end_points['Predictions']\n",
    "    predictions                = tf.argmax(probabilities, 1)\n",
    "\n",
    "    accuracy, accuracy_update  = tf.contrib.metrics.streaming_accuracy(predictions, labels)\n",
    "    top5_acc, top5_acc_update  = tf.contrib.metrics.streaming_sparse_recall_at_k(probabilities, labels, 5)\n",
    "\n",
    "    metrics_op                 = tf.group(accuracy_update, top5_acc_update)\n",
    "    \n",
    "stream_vars = [i for i in tf.local_variables() if i.name.split('/')[0] == 'metrics']\n",
    "reset_op = [tf.variables_initializer(stream_vars)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now finally create all the summaries you need to monitor and group them into one summary op.\n",
    "\n",
    "with tf.name_scope('training_summaries'):\n",
    "\n",
    "    train_loss    = tf.summary.scalar('total_Loss', total_loss)\n",
    "    train_t1_acc  = tf.summary.scalar('top1-accuracy', accuracy)\n",
    "    train_t5_acc  = tf.summary.scalar('top5-accuracy', top5_acc)\n",
    "    train_lr      = tf.summary.scalar('learning_rate', lr)\n",
    "\n",
    "    training_summary_op =   tf.summary.merge(\n",
    "        [train_loss, train_t1_acc, train_t5_acc, train_lr], \n",
    "        name=\"train__summaries\"\n",
    "    )\n",
    "    \n",
    "with tf.name_scope('validation_summaries'):\n",
    "\n",
    "    validation_loss    = tf.summary.scalar('total_Loss', total_loss)\n",
    "    validation_t1_acc  = tf.summary.scalar('top1-accuracy', accuracy)\n",
    "    validation_t5_acc  = tf.summary.scalar('top5-accuracy', top5_acc)\n",
    "    validation_lr      = tf.summary.scalar('learning_rate', lr)\n",
    "\n",
    "    validation_summary_op =   tf.summary.merge(\n",
    "        [validation_loss, validation_t1_acc, validation_t5_acc, validation_lr], \n",
    "        name=\"validation__summaries\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now we need to create a training step function that runs both the train_op, metrics_op and updates the global_step concurrently.\n",
    "def train_step(sess, train_op, global_step):\n",
    "    '''\n",
    "    Simply runs a session for the three arguments provided and gives a logging on the time elapsed for each global step\n",
    "    '''\n",
    "    #Check the time for each sess run\n",
    "    start_time = time.time()\n",
    "    total_loss, global_step_count, _ = sess.run([train_op, global_step, metrics_op], feed_dict={training_step: True})\n",
    "    time_elapsed = time.time() - start_time\n",
    "\n",
    "    #Run the logging to print some results\n",
    "    logging.info('Training Step %s: loss: %.4f (%.2f sec/step)', global_step_count, total_loss, time_elapsed)\n",
    "\n",
    "    return total_loss, global_step_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create a evaluation step function\n",
    "def perform_validation(sess):\n",
    "    '''\n",
    "    Simply read all the validation batches and run a classification run\n",
    "    '''\n",
    "    \n",
    "    sess.run(reset_op) # We reset the streaming Metrics for validation check\n",
    "\n",
    "    for val_step in range(num_validation_steps_per_epoch):\n",
    "        if (val_step % 100  == 0 and val_step != 0):\n",
    "            logging.info('Validation: Running Val Step: %s', val_step)\n",
    "        _ = sess.run(metrics_op, feed_dict={training_step: False})\n",
    "\n",
    "    accuracy_value, top5_acc_value = sess.run([accuracy, top5_acc])\n",
    "\n",
    "    logging.info('Validation: Top-1 Accuracy: %s', accuracy_value)\n",
    "    logging.info('Validation: Top-5 Accuracy: %s', top5_acc_value)\n",
    "\n",
    "    sv.summary_computed(\n",
    "        sess, \n",
    "        sess.run(validation_summary_op, feed_dict={training_step: False})\n",
    "    )\n",
    "\n",
    "    sess.run(reset_op) # We reset the streaming Metrics for the next training epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now we create a saver function that actually restores the variables from a checkpoint file in a sess\n",
    "restore_saver = tf.train.Saver(\n",
    "    var_list      = variables_to_restore,\n",
    "    write_version = FLAGS.tf_saver\n",
    ")\n",
    "\n",
    "def restore_fn(sess):\n",
    "    return restore_saver.restore(sess, checkpoint_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define your supervisor for running a managed session. \n",
    "#Do not run the summary_op automatically or else it will consume too much memory\n",
    "\n",
    "saving_saver = tf.train.Saver(\n",
    "    var_list      = variables_to_save,\n",
    "    write_version = FLAGS.tf_saver, \n",
    "    max_to_keep   = FLAGS.training_epochs\n",
    ")\n",
    "\n",
    "sv = tf.train.Supervisor(\n",
    "    logdir                = FLAGS.output_dir,\n",
    "    summary_op            = None, \n",
    "    init_fn               = restore_fn,\n",
    "    checkpoint_basename   = FLAGS.checkpoint_basename,\n",
    "    save_model_secs       = None, # Prevent Automatic Model saving\n",
    "    saver                 = saving_saver\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from inception_files\\models\\inception_v1.ckpt\n",
      "INFO:tensorflow:\n",
      "###################################\n",
      "\n",
      "INFO:tensorflow:Number of Training Epochs: 1\n",
      "INFO:tensorflow:Number of Training Steps per Epoch: 804\n",
      "INFO:tensorflow:Total Number of Training Steps: 804\n",
      "\n",
      "INFO:tensorflow:Number of Validation Runs: 1\n",
      "INFO:tensorflow:Number of Validation Steps per Validation Run: 536\n",
      "INFO:tensorflow:Total Number of Validation Steps: 536\n",
      "\n",
      "INFO:tensorflow:Total Number of Steps: 1340\n",
      "\n",
      "INFO:tensorflow:Summary Recorded Every 80 Training Steps\n",
      "INFO:tensorflow:\n",
      "###################################\n",
      "\n",
      "INFO:tensorflow:global_step/sec: 0\n",
      "INFO:tensorflow:Epoch 1/1\n",
      "INFO:tensorflow:Training: Learning Rate: 0.0001\n",
      "INFO:tensorflow:Training: Top-1 Accuracy: 0.0\n",
      "INFO:tensorflow:Training: Top-5 Accuracy: nan\n",
      "INFO:tensorflow:Validation: Running Val Step: 100\n",
      "INFO:tensorflow:Validation: Running Val Step: 200\n",
      "INFO:tensorflow:global_step/sec: 0\n",
      "INFO:tensorflow:Validation: Running Val Step: 300\n",
      "INFO:tensorflow:Validation: Running Val Step: 400\n",
      "INFO:tensorflow:global_step/sec: 0\n",
      "INFO:tensorflow:Validation: Running Val Step: 500\n",
      "INFO:tensorflow:Validation: Top-1 Accuracy: 0.231519\n",
      "INFO:tensorflow:Validation: Top-5 Accuracy: 0.602743634767\n",
      "INFO:tensorflow:Training Step 1: loss: 1.9762 (5.59 sec/step)\n",
      "INFO:tensorflow:Training Step 2: loss: 2.0162 (0.97 sec/step)\n",
      "INFO:tensorflow:Training Step 3: loss: 1.8141 (0.96 sec/step)\n",
      "INFO:tensorflow:Training Step 4: loss: 1.6451 (0.99 sec/step)\n",
      "INFO:tensorflow:Training Step 5: loss: 1.5542 (1.06 sec/step)\n",
      "INFO:tensorflow:Training Step 6: loss: 1.3970 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 7: loss: 1.5793 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 8: loss: 1.4033 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 9: loss: 1.2457 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 10: loss: 1.2540 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 11: loss: 1.3218 (1.17 sec/step)\n",
      "INFO:tensorflow:Training Step 12: loss: 1.1166 (1.17 sec/step)\n",
      "INFO:tensorflow:Training Step 13: loss: 1.1474 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 14: loss: 1.0947 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 15: loss: 1.1341 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 16: loss: 1.0322 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 17: loss: 1.0413 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 18: loss: 1.1104 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 19: loss: 0.9642 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 20: loss: 0.9437 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 21: loss: 0.9590 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 22: loss: 1.0273 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 23: loss: 0.9893 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 24: loss: 0.9999 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 25: loss: 0.9679 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 26: loss: 1.0003 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 27: loss: 0.8901 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 28: loss: 0.7684 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 29: loss: 0.8542 (1.17 sec/step)\n",
      "INFO:tensorflow:Training Step 30: loss: 0.7955 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 31: loss: 0.9886 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 32: loss: 0.7288 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 33: loss: 0.7900 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 34: loss: 0.8145 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 35: loss: 0.7495 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 36: loss: 0.8548 (1.17 sec/step)\n",
      "INFO:tensorflow:Training Step 37: loss: 0.8831 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 38: loss: 0.5914 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 39: loss: 0.7187 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 40: loss: 0.7232 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 41: loss: 0.7154 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 42: loss: 0.7515 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 43: loss: 0.5264 (1.17 sec/step)\n",
      "INFO:tensorflow:Training Step 44: loss: 0.7548 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 45: loss: 0.7119 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 46: loss: 0.6915 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 47: loss: 0.6837 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 48: loss: 0.7786 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 49: loss: 0.6392 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 50: loss: 0.6064 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 51: loss: 0.6965 (1.17 sec/step)\n",
      "INFO:tensorflow:Training Step 52: loss: 0.8642 (1.16 sec/step)\n",
      "INFO:tensorflow:Training Step 53: loss: 0.5984 (1.17 sec/step)\n",
      "INFO:tensorflow:Training Step 54: loss: 0.5116 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 55: loss: 0.6456 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 56: loss: 0.5830 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 57: loss: 0.6970 (1.17 sec/step)\n",
      "INFO:tensorflow:Training Step 58: loss: 0.6061 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 59: loss: 0.7962 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 60: loss: 0.8022 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 61: loss: 0.6376 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 62: loss: 0.7929 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 63: loss: 0.6472 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 64: loss: 0.6899 (1.17 sec/step)\n",
      "INFO:tensorflow:Training Step 65: loss: 0.7316 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 66: loss: 0.8493 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 67: loss: 0.6579 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 68: loss: 0.7167 (1.19 sec/step)\n",
      "INFO:tensorflow:global_step/sec: 0.566705\n",
      "INFO:tensorflow:Training Step 69: loss: 0.6526 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 70: loss: 0.5001 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 71: loss: 0.6449 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 72: loss: 0.7409 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 73: loss: 0.6575 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 74: loss: 0.6113 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 75: loss: 0.6066 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 76: loss: 0.5703 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 77: loss: 0.5449 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 78: loss: 0.7085 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 79: loss: 0.6695 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 80: loss: 0.6717 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 81: loss: 0.7593 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 82: loss: 0.6395 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 83: loss: 0.7950 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 84: loss: 0.5620 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 85: loss: 0.5560 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 86: loss: 0.7133 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 87: loss: 0.5823 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 88: loss: 0.5469 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 89: loss: 0.7457 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 90: loss: 0.5742 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 91: loss: 0.6310 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 92: loss: 0.5506 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 93: loss: 0.6921 (1.17 sec/step)\n",
      "INFO:tensorflow:Training Step 94: loss: 0.5296 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 95: loss: 0.4805 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 96: loss: 0.5951 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 97: loss: 0.6126 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 98: loss: 0.6491 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 99: loss: 0.5321 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 100: loss: 0.5890 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 101: loss: 0.7371 (1.17 sec/step)\n",
      "INFO:tensorflow:Training Step 102: loss: 0.6856 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 103: loss: 0.6104 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 104: loss: 0.6128 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 105: loss: 0.6935 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 106: loss: 0.6826 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 107: loss: 0.6025 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 108: loss: 0.6398 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 109: loss: 0.7246 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 110: loss: 0.6162 (1.17 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Training Step 111: loss: 0.4474 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 112: loss: 0.5345 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 113: loss: 0.5768 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 114: loss: 0.5555 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 115: loss: 0.6358 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 116: loss: 0.5492 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 117: loss: 0.5513 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 118: loss: 0.4759 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 119: loss: 0.5154 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 120: loss: 0.4982 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 121: loss: 0.4946 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 122: loss: 0.6366 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 123: loss: 0.5040 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 124: loss: 0.5811 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 125: loss: 0.7133 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 126: loss: 0.5532 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 127: loss: 0.5404 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 128: loss: 0.5245 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 129: loss: 0.4955 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 130: loss: 0.4605 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 131: loss: 0.5197 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 132: loss: 0.5246 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 133: loss: 0.6005 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 134: loss: 0.5752 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 135: loss: 0.6132 (1.17 sec/step)\n",
      "INFO:tensorflow:Training Step 136: loss: 0.5666 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 137: loss: 0.6513 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 138: loss: 0.6370 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 139: loss: 0.4389 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 140: loss: 0.5330 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 141: loss: 0.5177 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 142: loss: 0.5150 (1.23 sec/step)\n",
      "INFO:tensorflow:Training Step 143: loss: 0.5378 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 144: loss: 0.6382 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 145: loss: 0.6397 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 146: loss: 0.6225 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 147: loss: 0.5547 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 148: loss: 0.5116 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 149: loss: 0.5430 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 150: loss: 0.5355 (1.22 sec/step)\n",
      "INFO:tensorflow:Training Step 151: loss: 0.6291 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 152: loss: 0.6527 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 153: loss: 0.5113 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 154: loss: 0.5754 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 155: loss: 0.4844 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 156: loss: 0.5720 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 157: loss: 0.5664 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 158: loss: 0.5607 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 159: loss: 0.5293 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 160: loss: 0.5370 (1.22 sec/step)\n",
      "INFO:tensorflow:Training Step 161: loss: 0.4974 (1.23 sec/step)\n",
      "INFO:tensorflow:Training Step 162: loss: 0.4985 (1.23 sec/step)\n",
      "INFO:tensorflow:Training Step 163: loss: 0.6381 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 164: loss: 0.5938 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 165: loss: 0.7023 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 166: loss: 0.6283 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 167: loss: 0.6119 (1.19 sec/step)\n",
      "INFO:tensorflow:global_step/sec: 0.824935\n",
      "INFO:tensorflow:Training Step 168: loss: 0.5863 (1.17 sec/step)\n",
      "INFO:tensorflow:Training Step 169: loss: 0.6185 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 170: loss: 0.5571 (1.22 sec/step)\n",
      "INFO:tensorflow:Training Step 171: loss: 0.5407 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 172: loss: 0.6088 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 173: loss: 0.4274 (1.22 sec/step)\n",
      "INFO:tensorflow:Training Step 174: loss: 0.4678 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 175: loss: 0.5661 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 176: loss: 0.5432 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 177: loss: 0.7197 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 178: loss: 0.7434 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 179: loss: 0.5116 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 180: loss: 0.5650 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 181: loss: 0.5812 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 182: loss: 0.6401 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 183: loss: 0.5581 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 184: loss: 0.6023 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 185: loss: 0.4966 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 186: loss: 0.5657 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 187: loss: 0.4396 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 188: loss: 0.4790 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 189: loss: 0.4426 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 190: loss: 0.6001 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 191: loss: 0.5443 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 192: loss: 0.5952 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 193: loss: 0.6232 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 194: loss: 0.5191 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 195: loss: 0.4517 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 196: loss: 0.4944 (1.22 sec/step)\n",
      "INFO:tensorflow:Training Step 197: loss: 0.5547 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 198: loss: 0.5226 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 199: loss: 0.5433 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 200: loss: 0.3878 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 201: loss: 0.4351 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 202: loss: 0.5380 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 203: loss: 0.6504 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 204: loss: 0.5595 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 205: loss: 0.5760 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 206: loss: 0.4343 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 207: loss: 0.5485 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 208: loss: 0.4812 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 209: loss: 0.5483 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 210: loss: 0.5970 (1.23 sec/step)\n",
      "INFO:tensorflow:Training Step 211: loss: 0.5523 (1.22 sec/step)\n",
      "INFO:tensorflow:Training Step 212: loss: 0.5678 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 213: loss: 0.4351 (1.22 sec/step)\n",
      "INFO:tensorflow:Training Step 214: loss: 0.4729 (1.24 sec/step)\n",
      "INFO:tensorflow:Training Step 215: loss: 0.4599 (1.22 sec/step)\n",
      "INFO:tensorflow:Training Step 216: loss: 0.5021 (1.22 sec/step)\n",
      "INFO:tensorflow:Training Step 217: loss: 0.5051 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 218: loss: 0.5185 (1.25 sec/step)\n",
      "INFO:tensorflow:Training Step 219: loss: 0.4109 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 220: loss: 0.4582 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 221: loss: 0.6347 (1.17 sec/step)\n",
      "INFO:tensorflow:Training Step 222: loss: 0.5226 (1.22 sec/step)\n",
      "INFO:tensorflow:Training Step 223: loss: 0.4777 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 224: loss: 0.5013 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 225: loss: 0.5416 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 226: loss: 0.4069 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 227: loss: 0.5173 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 228: loss: 0.4602 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 229: loss: 0.5251 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 230: loss: 0.3966 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 231: loss: 0.4741 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 232: loss: 0.4377 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 233: loss: 0.4902 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 234: loss: 0.4424 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 235: loss: 0.6739 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 236: loss: 0.5253 (1.22 sec/step)\n",
      "INFO:tensorflow:Training Step 237: loss: 0.6004 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 238: loss: 0.4485 (1.20 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Training Step 239: loss: 0.4965 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 240: loss: 0.5433 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 241: loss: 0.3889 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 242: loss: 0.4296 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 243: loss: 0.4074 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 244: loss: 0.4884 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 245: loss: 0.5022 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 246: loss: 0.4420 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 247: loss: 0.4982 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 248: loss: 0.5033 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 249: loss: 0.4858 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 250: loss: 0.4775 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 251: loss: 0.4668 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 252: loss: 0.6183 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 253: loss: 0.4450 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 254: loss: 0.5133 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 255: loss: 0.4472 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 256: loss: 0.4174 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 257: loss: 0.6019 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 258: loss: 0.3823 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 259: loss: 0.4642 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 260: loss: 0.5459 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 261: loss: 0.6293 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 262: loss: 0.4281 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 263: loss: 0.3806 (1.17 sec/step)\n",
      "INFO:tensorflow:Training Step 264: loss: 0.5010 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 265: loss: 0.4935 (1.22 sec/step)\n",
      "INFO:tensorflow:Training Step 266: loss: 0.4823 (1.17 sec/step)\n",
      "INFO:tensorflow:Training Step 267: loss: 0.5116 (1.21 sec/step)\n",
      "INFO:tensorflow:global_step/sec: 0.833443\n",
      "INFO:tensorflow:Training Step 268: loss: 0.6413 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 269: loss: 0.5219 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 270: loss: 0.4175 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 271: loss: 0.5120 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 272: loss: 0.4243 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 273: loss: 0.5239 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 274: loss: 0.5138 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 275: loss: 0.5066 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 276: loss: 0.6141 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 277: loss: 0.4192 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 278: loss: 0.4400 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 279: loss: 0.3592 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 280: loss: 0.4817 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 281: loss: 0.5156 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 282: loss: 0.4114 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 283: loss: 0.6736 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 284: loss: 0.4492 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 285: loss: 0.5483 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 286: loss: 0.5306 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 287: loss: 0.4522 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 288: loss: 0.5435 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 289: loss: 0.4160 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 290: loss: 0.3327 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 291: loss: 0.4472 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 292: loss: 0.5150 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 293: loss: 0.4057 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 294: loss: 0.4795 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 295: loss: 0.5356 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 296: loss: 0.4809 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 297: loss: 0.3815 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 298: loss: 0.4908 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 299: loss: 0.4440 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 300: loss: 0.4539 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 301: loss: 0.6272 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 302: loss: 0.5888 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 303: loss: 0.4480 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 304: loss: 0.4550 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 305: loss: 0.4083 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 306: loss: 0.5496 (1.22 sec/step)\n",
      "INFO:tensorflow:Training Step 307: loss: 0.7076 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 308: loss: 0.4179 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 309: loss: 0.6435 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 310: loss: 0.5317 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 311: loss: 0.5671 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 312: loss: 0.6969 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 313: loss: 0.5220 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 314: loss: 0.4866 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 315: loss: 0.4927 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 316: loss: 0.5463 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 317: loss: 0.4045 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 318: loss: 0.4527 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 319: loss: 0.4363 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 320: loss: 0.4591 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 321: loss: 0.4244 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 322: loss: 0.5327 (1.22 sec/step)\n",
      "INFO:tensorflow:Training Step 323: loss: 0.4888 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 324: loss: 0.4432 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 325: loss: 0.5071 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 326: loss: 0.4593 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 327: loss: 0.3491 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 328: loss: 0.5344 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 329: loss: 0.4751 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 330: loss: 0.4796 (1.22 sec/step)\n",
      "INFO:tensorflow:Training Step 331: loss: 0.4142 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 332: loss: 0.4051 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 333: loss: 0.3860 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 334: loss: 0.5125 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 335: loss: 0.4055 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 336: loss: 0.5147 (1.24 sec/step)\n",
      "INFO:tensorflow:Training Step 337: loss: 0.3990 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 338: loss: 0.4437 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 339: loss: 0.4936 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 340: loss: 0.3845 (1.22 sec/step)\n",
      "INFO:tensorflow:Training Step 341: loss: 0.5154 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 342: loss: 0.5300 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 343: loss: 0.4779 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 344: loss: 0.4251 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 345: loss: 0.4403 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 346: loss: 0.5248 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 347: loss: 0.4482 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 348: loss: 0.3943 (1.22 sec/step)\n",
      "INFO:tensorflow:Training Step 349: loss: 0.4787 (1.17 sec/step)\n",
      "INFO:tensorflow:Training Step 350: loss: 0.5614 (1.22 sec/step)\n",
      "INFO:tensorflow:Training Step 351: loss: 0.4933 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 352: loss: 0.4570 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 353: loss: 0.4237 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 354: loss: 0.4042 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 355: loss: 0.5352 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 356: loss: 0.5553 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 357: loss: 0.5284 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 358: loss: 0.3783 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 359: loss: 0.5494 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 360: loss: 0.4801 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 361: loss: 0.5053 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 362: loss: 0.6526 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 363: loss: 0.5700 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 364: loss: 0.4248 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 365: loss: 0.4884 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 366: loss: 0.5960 (1.20 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.824898\n",
      "INFO:tensorflow:Training Step 367: loss: 0.4247 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 368: loss: 0.4654 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 369: loss: 0.3445 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 370: loss: 0.4408 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 371: loss: 0.4415 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 372: loss: 0.5293 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 373: loss: 0.5176 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 374: loss: 0.4138 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 375: loss: 0.4384 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 376: loss: 0.4936 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 377: loss: 0.3786 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 378: loss: 0.4808 (1.17 sec/step)\n",
      "INFO:tensorflow:Training Step 379: loss: 0.2891 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 380: loss: 0.5637 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 381: loss: 0.3936 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 382: loss: 0.3209 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 383: loss: 0.4442 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 384: loss: 0.3671 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 385: loss: 0.4009 (1.22 sec/step)\n",
      "INFO:tensorflow:Training Step 386: loss: 0.3859 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 387: loss: 0.4666 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 388: loss: 0.5579 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 389: loss: 0.3974 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 390: loss: 0.4668 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 391: loss: 0.5780 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 392: loss: 0.3393 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 393: loss: 0.4596 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 394: loss: 0.4213 (1.22 sec/step)\n",
      "INFO:tensorflow:Training Step 395: loss: 0.4093 (1.22 sec/step)\n",
      "INFO:tensorflow:Training Step 396: loss: 0.4389 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 397: loss: 0.4156 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 398: loss: 0.3620 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 399: loss: 0.4379 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 400: loss: 0.3520 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 401: loss: 0.5848 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 402: loss: 0.4243 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 403: loss: 0.4286 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 404: loss: 0.2923 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 405: loss: 0.4715 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 406: loss: 0.5331 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 407: loss: 0.4677 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 408: loss: 0.3506 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 409: loss: 0.3726 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 410: loss: 0.7271 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 411: loss: 0.4507 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 412: loss: 0.4829 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 413: loss: 0.4238 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 414: loss: 0.5663 (1.17 sec/step)\n",
      "INFO:tensorflow:Training Step 415: loss: 0.4024 (1.22 sec/step)\n",
      "INFO:tensorflow:Training Step 416: loss: 0.4299 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 417: loss: 0.3543 (1.23 sec/step)\n",
      "INFO:tensorflow:Training Step 418: loss: 0.3630 (1.22 sec/step)\n",
      "INFO:tensorflow:Training Step 419: loss: 0.4728 (1.22 sec/step)\n",
      "INFO:tensorflow:Training Step 420: loss: 0.3615 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 421: loss: 0.3217 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 422: loss: 0.4133 (1.22 sec/step)\n",
      "INFO:tensorflow:Training Step 423: loss: 0.6303 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 424: loss: 0.4201 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 425: loss: 0.3641 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 426: loss: 0.3188 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 427: loss: 0.4548 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 428: loss: 0.4946 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 429: loss: 0.4115 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 430: loss: 0.3717 (1.22 sec/step)\n",
      "INFO:tensorflow:Training Step 431: loss: 0.3709 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 432: loss: 0.4290 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 433: loss: 0.4712 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 434: loss: 0.4616 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 435: loss: 0.4211 (1.23 sec/step)\n",
      "INFO:tensorflow:Training Step 436: loss: 0.5213 (1.46 sec/step)\n",
      "INFO:tensorflow:Training Step 437: loss: 0.3596 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 438: loss: 0.3653 (1.17 sec/step)\n",
      "INFO:tensorflow:Training Step 439: loss: 0.4256 (1.17 sec/step)\n",
      "INFO:tensorflow:Training Step 440: loss: 0.3963 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 441: loss: 0.4825 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 442: loss: 0.3578 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 443: loss: 0.4681 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 444: loss: 0.3704 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 445: loss: 0.4672 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 446: loss: 0.4623 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 447: loss: 0.3762 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 448: loss: 0.3615 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 449: loss: 0.4322 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 450: loss: 0.4728 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 451: loss: 0.5034 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 452: loss: 0.4975 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 453: loss: 0.3762 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 454: loss: 0.4971 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 455: loss: 0.3585 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 456: loss: 0.4059 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 457: loss: 0.3620 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 458: loss: 0.4638 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 459: loss: 0.4136 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 460: loss: 0.4685 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 461: loss: 0.4394 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 462: loss: 0.5011 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 463: loss: 0.3981 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 464: loss: 0.6845 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 465: loss: 0.3817 (1.20 sec/step)\n",
      "INFO:tensorflow:global_step/sec: 0.833337\n",
      "INFO:tensorflow:Training Step 466: loss: 0.4154 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 467: loss: 0.3544 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 468: loss: 0.4113 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 469: loss: 0.4270 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 470: loss: 0.4247 (1.23 sec/step)\n",
      "INFO:tensorflow:Training Step 471: loss: 0.5150 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 472: loss: 0.3921 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 473: loss: 0.4774 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 474: loss: 0.4568 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 475: loss: 0.4487 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 476: loss: 0.4219 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 477: loss: 0.4758 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 478: loss: 0.4789 (1.17 sec/step)\n",
      "INFO:tensorflow:Training Step 479: loss: 0.3787 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 480: loss: 0.3818 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 481: loss: 0.3699 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 482: loss: 0.3745 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 483: loss: 0.3454 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 484: loss: 0.5774 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 485: loss: 0.4940 (1.17 sec/step)\n",
      "INFO:tensorflow:Training Step 486: loss: 0.3525 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 487: loss: 0.3198 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 488: loss: 0.5219 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 489: loss: 0.5788 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 490: loss: 0.5022 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 491: loss: 0.3441 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 492: loss: 0.3489 (1.17 sec/step)\n",
      "INFO:tensorflow:Training Step 493: loss: 0.3178 (1.20 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Training Step 494: loss: 0.4271 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 495: loss: 0.5890 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 496: loss: 0.4543 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 497: loss: 0.3910 (1.24 sec/step)\n",
      "INFO:tensorflow:Training Step 498: loss: 0.4935 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 499: loss: 0.4088 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 500: loss: 0.4229 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 501: loss: 0.4459 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 502: loss: 0.3991 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 503: loss: 0.3189 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 504: loss: 0.5133 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 505: loss: 0.4066 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 506: loss: 0.5394 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 507: loss: 0.4724 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 508: loss: 0.3242 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 509: loss: 0.3492 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 510: loss: 0.4151 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 511: loss: 0.5461 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 512: loss: 0.4810 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 513: loss: 0.3994 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 514: loss: 0.3987 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 515: loss: 0.3912 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 516: loss: 0.3925 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 517: loss: 0.5692 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 518: loss: 0.4424 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 519: loss: 0.5923 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 520: loss: 0.3425 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 521: loss: 0.4295 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 522: loss: 0.4317 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 523: loss: 0.4098 (1.22 sec/step)\n",
      "INFO:tensorflow:Training Step 524: loss: 0.3592 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 525: loss: 0.4557 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 526: loss: 0.3900 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 527: loss: 0.4241 (1.17 sec/step)\n",
      "INFO:tensorflow:Training Step 528: loss: 0.4579 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 529: loss: 0.4082 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 530: loss: 0.4031 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 531: loss: 0.4140 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 532: loss: 0.3215 (1.22 sec/step)\n",
      "INFO:tensorflow:Training Step 533: loss: 0.4051 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 534: loss: 0.5275 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 535: loss: 0.4166 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 536: loss: 0.4177 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 537: loss: 0.5577 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 538: loss: 0.4385 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 539: loss: 0.4040 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 540: loss: 0.3183 (1.24 sec/step)\n",
      "INFO:tensorflow:Training Step 541: loss: 0.3627 (1.17 sec/step)\n",
      "INFO:tensorflow:Training Step 542: loss: 0.3754 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 543: loss: 0.3328 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 544: loss: 0.4119 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 545: loss: 0.3977 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 546: loss: 0.3581 (1.16 sec/step)\n",
      "INFO:tensorflow:Training Step 547: loss: 0.4149 (1.17 sec/step)\n",
      "INFO:tensorflow:Training Step 548: loss: 0.5026 (1.17 sec/step)\n",
      "INFO:tensorflow:Training Step 549: loss: 0.3230 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 550: loss: 0.3624 (1.62 sec/step)\n",
      "INFO:tensorflow:Training Step 551: loss: 0.3628 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 552: loss: 0.3605 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 553: loss: 0.3907 (1.23 sec/step)\n",
      "INFO:tensorflow:Training Step 554: loss: 0.4389 (1.22 sec/step)\n",
      "INFO:tensorflow:Training Step 555: loss: 0.2997 (1.22 sec/step)\n",
      "INFO:tensorflow:Training Step 556: loss: 0.4851 (1.23 sec/step)\n",
      "INFO:tensorflow:Training Step 557: loss: 0.4074 (1.22 sec/step)\n",
      "INFO:tensorflow:Training Step 558: loss: 0.4919 (1.23 sec/step)\n",
      "INFO:tensorflow:Training Step 559: loss: 0.3490 (1.25 sec/step)\n",
      "INFO:tensorflow:Training Step 560: loss: 0.4116 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 561: loss: 0.4529 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 562: loss: 0.3993 (1.22 sec/step)\n",
      "INFO:tensorflow:Training Step 563: loss: 0.5044 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 564: loss: 0.3853 (1.19 sec/step)\n",
      "INFO:tensorflow:global_step/sec: 0.816682\n",
      "INFO:tensorflow:Training Step 565: loss: 0.4880 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 566: loss: 0.2918 (1.17 sec/step)\n",
      "INFO:tensorflow:Training Step 567: loss: 0.5467 (1.22 sec/step)\n",
      "INFO:tensorflow:Training Step 568: loss: 0.4329 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 569: loss: 0.5273 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 570: loss: 0.6332 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 571: loss: 0.3689 (1.22 sec/step)\n",
      "INFO:tensorflow:Training Step 572: loss: 0.5442 (1.23 sec/step)\n",
      "INFO:tensorflow:Training Step 573: loss: 0.3374 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 574: loss: 0.3590 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 575: loss: 0.3464 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 576: loss: 0.4516 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 577: loss: 0.3549 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 578: loss: 0.4535 (1.22 sec/step)\n",
      "INFO:tensorflow:Training Step 579: loss: 0.3728 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 580: loss: 0.4135 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 581: loss: 0.3052 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 582: loss: 0.3404 (1.23 sec/step)\n",
      "INFO:tensorflow:Training Step 583: loss: 0.5272 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 584: loss: 0.3719 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 585: loss: 0.4237 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 586: loss: 0.3512 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 587: loss: 0.3924 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 588: loss: 0.3380 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 589: loss: 0.4152 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 590: loss: 0.4204 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 591: loss: 0.5445 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 592: loss: 0.3300 (1.22 sec/step)\n",
      "INFO:tensorflow:Training Step 593: loss: 0.3810 (1.22 sec/step)\n",
      "INFO:tensorflow:Training Step 594: loss: 0.3845 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 595: loss: 0.4446 (1.22 sec/step)\n",
      "INFO:tensorflow:Training Step 596: loss: 0.4953 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 597: loss: 0.3787 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 598: loss: 0.4950 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 599: loss: 0.3260 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 600: loss: 0.4195 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 601: loss: 0.4174 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 602: loss: 0.5358 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 603: loss: 0.4694 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 604: loss: 0.4142 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 605: loss: 0.3164 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 606: loss: 0.3500 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 607: loss: 0.4263 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 608: loss: 0.3849 (1.22 sec/step)\n",
      "INFO:tensorflow:Training Step 609: loss: 0.4403 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 610: loss: 0.5415 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 611: loss: 0.3529 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 612: loss: 0.3338 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 613: loss: 0.3777 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 614: loss: 0.3932 (1.43 sec/step)\n",
      "INFO:tensorflow:Training Step 615: loss: 0.3982 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 616: loss: 0.5762 (1.14 sec/step)\n",
      "INFO:tensorflow:Training Step 617: loss: 0.3134 (1.17 sec/step)\n",
      "INFO:tensorflow:Training Step 618: loss: 0.3390 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 619: loss: 0.3391 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 620: loss: 0.4833 (1.17 sec/step)\n",
      "INFO:tensorflow:Training Step 621: loss: 0.4295 (1.20 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Training Step 622: loss: 0.3126 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 623: loss: 0.3543 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 624: loss: 0.4230 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 625: loss: 0.6437 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 626: loss: 0.3221 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 627: loss: 0.4847 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 628: loss: 0.3784 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 629: loss: 0.3400 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 630: loss: 0.3367 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 631: loss: 0.4882 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 632: loss: 0.4596 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 633: loss: 0.3650 (1.23 sec/step)\n",
      "INFO:tensorflow:Training Step 634: loss: 0.3348 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 635: loss: 0.4508 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 636: loss: 0.3958 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 637: loss: 0.3357 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 638: loss: 0.4634 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 639: loss: 0.3443 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 640: loss: 0.3668 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 641: loss: 0.4126 (1.22 sec/step)\n",
      "INFO:tensorflow:Training Step 642: loss: 0.3422 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 643: loss: 0.3157 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 644: loss: 0.4048 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 645: loss: 0.4655 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 646: loss: 0.3830 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 647: loss: 0.4548 (1.22 sec/step)\n",
      "INFO:tensorflow:Training Step 648: loss: 0.5113 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 649: loss: 0.5032 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 650: loss: 0.3188 (1.17 sec/step)\n",
      "INFO:tensorflow:Training Step 651: loss: 0.4503 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 652: loss: 0.4707 (1.17 sec/step)\n",
      "INFO:tensorflow:Training Step 653: loss: 0.4153 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 654: loss: 0.3069 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 655: loss: 0.4706 (1.23 sec/step)\n",
      "INFO:tensorflow:Training Step 656: loss: 0.3170 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 657: loss: 0.4094 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 658: loss: 0.3362 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 659: loss: 0.3769 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 660: loss: 0.4795 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 661: loss: 0.4145 (1.22 sec/step)\n",
      "INFO:tensorflow:Training Step 662: loss: 0.3535 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 663: loss: 0.3201 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 664: loss: 0.2952 (1.19 sec/step)\n",
      "INFO:tensorflow:global_step/sec: 0.833365\n",
      "INFO:tensorflow:Training Step 665: loss: 0.4371 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 666: loss: 0.4715 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 667: loss: 0.4020 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 668: loss: 0.4898 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 669: loss: 0.2997 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 670: loss: 0.4014 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 671: loss: 0.4164 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 672: loss: 0.3413 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 673: loss: 0.4310 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 674: loss: 0.3513 (1.16 sec/step)\n",
      "INFO:tensorflow:Training Step 675: loss: 0.3666 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 676: loss: 0.3789 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 677: loss: 0.2950 (1.17 sec/step)\n",
      "INFO:tensorflow:Training Step 678: loss: 0.5157 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 679: loss: 0.4148 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 680: loss: 0.3392 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 681: loss: 0.4212 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 682: loss: 0.4165 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 683: loss: 0.3612 (1.17 sec/step)\n",
      "INFO:tensorflow:Training Step 684: loss: 0.4668 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 685: loss: 0.3795 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 686: loss: 0.4273 (1.22 sec/step)\n",
      "INFO:tensorflow:Training Step 687: loss: 0.3534 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 688: loss: 0.3589 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 689: loss: 0.3495 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 690: loss: 0.3417 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 691: loss: 0.3880 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 692: loss: 0.4437 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 693: loss: 0.4019 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 694: loss: 0.4545 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 695: loss: 0.3220 (1.22 sec/step)\n",
      "INFO:tensorflow:Training Step 696: loss: 0.3965 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 697: loss: 0.3352 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 698: loss: 0.3250 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 699: loss: 0.3348 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 700: loss: 0.4059 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 701: loss: 0.4009 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 702: loss: 0.3453 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 703: loss: 0.3036 (1.23 sec/step)\n",
      "INFO:tensorflow:Training Step 704: loss: 0.4083 (1.17 sec/step)\n",
      "INFO:tensorflow:Training Step 705: loss: 0.4321 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 706: loss: 0.4081 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 707: loss: 0.4768 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 708: loss: 0.3636 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 709: loss: 0.4053 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 710: loss: 0.3605 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 711: loss: 0.2681 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 712: loss: 0.4077 (1.22 sec/step)\n",
      "INFO:tensorflow:Training Step 713: loss: 0.3978 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 714: loss: 0.4667 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 715: loss: 0.5254 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 716: loss: 0.5477 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 717: loss: 0.3132 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 718: loss: 0.3959 (1.17 sec/step)\n",
      "INFO:tensorflow:Training Step 719: loss: 0.3189 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 720: loss: 0.3483 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 721: loss: 0.3940 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 722: loss: 0.5901 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 723: loss: 0.4637 (1.17 sec/step)\n",
      "INFO:tensorflow:Training Step 724: loss: 0.3586 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 725: loss: 0.3829 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 726: loss: 0.2876 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 727: loss: 0.2891 (1.17 sec/step)\n",
      "INFO:tensorflow:Training Step 728: loss: 0.4799 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 729: loss: 0.3264 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 730: loss: 0.4289 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 731: loss: 0.5291 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 732: loss: 0.3880 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 733: loss: 0.3716 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 734: loss: 0.4778 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 735: loss: 0.4675 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 736: loss: 0.4630 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 737: loss: 0.4740 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 738: loss: 0.5115 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 739: loss: 0.4054 (1.17 sec/step)\n",
      "INFO:tensorflow:Training Step 740: loss: 0.4167 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 741: loss: 0.3758 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 742: loss: 0.2981 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 743: loss: 0.4307 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 744: loss: 0.3735 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 745: loss: 0.3633 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 746: loss: 0.4184 (1.22 sec/step)\n",
      "INFO:tensorflow:Training Step 747: loss: 0.3275 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 748: loss: 0.3992 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 749: loss: 0.3979 (1.21 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Training Step 750: loss: 0.4606 (1.23 sec/step)\n",
      "INFO:tensorflow:Training Step 751: loss: 0.4127 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 752: loss: 0.3324 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 753: loss: 0.3085 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 754: loss: 0.2908 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 755: loss: 0.4133 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 756: loss: 0.3504 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 757: loss: 0.3435 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 758: loss: 0.3384 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 759: loss: 0.4095 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 760: loss: 0.3568 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 761: loss: 0.3422 (1.17 sec/step)\n",
      "INFO:tensorflow:Training Step 762: loss: 0.4682 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 763: loss: 0.5133 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 764: loss: 0.4400 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 765: loss: 0.3874 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 766: loss: 0.2717 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 767: loss: 0.3703 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 768: loss: 0.2708 (1.17 sec/step)\n",
      "INFO:tensorflow:Training Step 769: loss: 0.4162 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 770: loss: 0.4244 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 771: loss: 0.3562 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 772: loss: 0.2929 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 773: loss: 0.4074 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 774: loss: 0.3898 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 775: loss: 0.3302 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 776: loss: 0.3831 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 777: loss: 0.3673 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 778: loss: 0.4204 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 779: loss: 0.2861 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 780: loss: 0.2641 (1.21 sec/step)\n",
      "INFO:tensorflow:Training Step 781: loss: 0.3802 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 782: loss: 0.4377 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 783: loss: 0.3409 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 784: loss: 0.3780 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 785: loss: 0.3046 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 786: loss: 0.3022 (1.17 sec/step)\n",
      "INFO:tensorflow:Training Step 787: loss: 0.2316 (1.22 sec/step)\n",
      "INFO:tensorflow:Training Step 788: loss: 0.3628 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 789: loss: 0.4619 (1.22 sec/step)\n",
      "INFO:tensorflow:Training Step 790: loss: 0.3335 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 791: loss: 0.3234 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 792: loss: 0.3236 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 793: loss: 0.5175 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 794: loss: 0.2830 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 795: loss: 0.3443 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 796: loss: 0.3375 (1.17 sec/step)\n",
      "INFO:tensorflow:Training Step 797: loss: 0.2807 (1.17 sec/step)\n",
      "INFO:tensorflow:Training Step 798: loss: 0.3539 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 799: loss: 0.4037 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 800: loss: 0.2984 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 801: loss: 0.3365 (1.18 sec/step)\n",
      "INFO:tensorflow:Training Step 802: loss: 0.3305 (1.19 sec/step)\n",
      "INFO:tensorflow:Training Step 803: loss: 0.3773 (1.20 sec/step)\n",
      "INFO:tensorflow:Training Step 804: loss: 0.3571 (1.21 sec/step)\n",
      "INFO:tensorflow:\n",
      "#############################################\n",
      "INFO:tensorflow:############## Final Statistics ##############\n",
      "INFO:tensorflow:#############################################\n",
      "\n",
      "INFO:tensorflow:Training: Loss: 0.357123\n",
      "INFO:tensorflow:Training: Learning Rate: 0.0001\n",
      "INFO:tensorflow:Training: Top-1 Accuracy: 0.883977\n",
      "INFO:tensorflow:Training: Top-5 Accuracy: 0.982440737489\n",
      "INFO:tensorflow:Validation: Running Val Step: 100\n",
      "INFO:tensorflow:Validation: Running Val Step: 200\n",
      "INFO:tensorflow:Validation: Running Val Step: 300\n",
      "INFO:tensorflow:Validation: Running Val Step: 400\n",
      "INFO:tensorflow:Validation: Running Val Step: 500\n",
      "INFO:tensorflow:Validation: Top-1 Accuracy: 0.970259\n",
      "INFO:tensorflow:Validation: Top-5 Accuracy: 0.998858647937\n",
      "INFO:tensorflow:Finished training! Saving model to disk now.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n"
     ]
    }
   ],
   "source": [
    "#Run the managed session\n",
    "with sv.managed_session() as sess:   \n",
    "    \n",
    "    logging.info(\"\\n###################################\\n\")\n",
    "    \n",
    "    total_training_steps   = num_training_steps_per_epoch * FLAGS.training_epochs\n",
    "    \n",
    "    total_validation_runs  = FLAGS.training_epochs // 3 + 1\n",
    "    total_validation_steps = num_validation_steps_per_epoch * total_validation_runs\n",
    "    \n",
    "    total_steps            = total_training_steps + total_validation_steps\n",
    "    \n",
    "    logging.info(\"Number of Training Epochs: %d\", FLAGS.training_epochs)\n",
    "    logging.info(\"Number of Training Steps per Epoch: %d\", num_training_steps_per_epoch)  \n",
    "    logging.info(\"Total Number of Training Steps: %d\\n\", total_training_steps)  \n",
    "    \n",
    "    logging.info(\"Number of Validation Runs: %d\", total_validation_runs)\n",
    "    logging.info(\"Number of Validation Steps per Validation Run: %d\", num_validation_steps_per_epoch)\n",
    "    logging.info(\"Total Number of Validation Steps: %d\\n\", total_validation_steps)  \n",
    "    \n",
    "    logging.info(\"Total Number of Steps: %d\\n\", total_steps) \n",
    "    \n",
    "    logging.info(\"Summary Recorded Every %d Training Steps\" % round(num_training_steps_per_epoch/10))\n",
    "    \n",
    "    logging.info(\"\\n###################################\\n\")\n",
    "    \n",
    "    for step in range(num_training_steps_per_epoch * FLAGS.training_epochs):\n",
    "            \n",
    "        #At the start of every epoch, show the vital information:\n",
    "        if step % num_training_steps_per_epoch == 0:\n",
    "            \n",
    "            learning_rate_value, accuracy_value, top5_acc_value = sess.run([lr, accuracy, top5_acc])\n",
    "            \n",
    "            logging.info('Epoch %d/%d', step/num_training_steps_per_epoch + 1, FLAGS.training_epochs)\n",
    "            \n",
    "            logging.info('Training: Learning Rate: %s', learning_rate_value)\n",
    "            logging.info('Training: Top-1 Accuracy: %s', accuracy_value)\n",
    "            logging.info('Training: Top-5 Accuracy: %s', top5_acc_value)\n",
    "            \n",
    "            # Compute Validation Metrics after 3 Epochs \n",
    "            \n",
    "            if step % (num_training_steps_per_epoch * 3) == 0: \n",
    "                perform_validation(sess)\n",
    "            \n",
    "            # Save Model after each Epoch\n",
    "            if step != 0:\n",
    "                sv.saver.save(sess, sv.save_path, global_step = sv.global_step)                    \n",
    "\n",
    "        #Log the summaries every 1-10th of epoch.\n",
    "        if (step % num_training_steps_per_epoch % round(num_training_steps_per_epoch/10)) == 0 :\n",
    "            loss, _ = train_step(sess, train_op, sv.global_step)\n",
    "            sv.summary_computed(\n",
    "                sess, \n",
    "                sess.run(training_summary_op, feed_dict={training_step: True})\n",
    "            )\n",
    "\n",
    "        #If not, simply run the training step\n",
    "        else:\n",
    "            loss, _ = train_step(sess, train_op, sv.global_step)\n",
    "\n",
    "    #We log the final training and validation statistics\n",
    "    \n",
    "    logging.info('\\n#############################################')\n",
    "    logging.info('############## Final Statistics ##############')\n",
    "    logging.info('#############################################\\n')\n",
    "    \n",
    "    logging.info('Training: Loss: %s', loss)\n",
    "    logging.info('Training: Learning Rate: %s', learning_rate_value)\n",
    "    logging.info('Training: Top-1 Accuracy: %s', sess.run(accuracy))\n",
    "    logging.info('Training: Top-5 Accuracy: %s', sess.run(top5_acc))\n",
    "    \n",
    "    perform_validation(sess) \n",
    "\n",
    "    #Once all the training has been done, save the log files and checkpoint model\n",
    "    logging.info('Finished training! Saving model to disk now.')\n",
    "    \n",
    "    sv.saver.save(sess, sv.save_path, global_step = sv.global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

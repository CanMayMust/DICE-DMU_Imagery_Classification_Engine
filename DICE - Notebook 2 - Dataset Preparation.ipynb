{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DICE - Notebook 2 - Dataset Preparation\n",
    "\n",
    "<br/>\n",
    "\n",
    "```\n",
    "*************************************************************************\n",
    "**\n",
    "** 2017 Mai 23\n",
    "**\n",
    "** In place of a legal notice, here is a blessing:\n",
    "**\n",
    "**    May you do good and not evil.\n",
    "**    May you find forgiveness for yourself and forgive others.\n",
    "**    May you share freely, never taking more than you give.\n",
    "**\n",
    "*************************************************************************\n",
    "```\n",
    "\n",
    "<table style=\"width:100%; font-size:14px; margin: 20px 0;\">\n",
    "    <tr>\n",
    "        <td style=\"text-align:center\">\n",
    "            <b>Contact: </b><a href=\"mailto:contact@jonathandekhtiar.eu\" target=\"_blank\">contact@jonathandekhtiar.eu</a>\n",
    "        </td>\n",
    "        <td style=\"text-align:center\">\n",
    "            <b>Twitter: </b><a href=\"https://twitter.com/born2data\" target=\"_blank\">@born2data</a>\n",
    "        </td>\n",
    "        <td style=\"text-align:center\">\n",
    "            <b>Tech. Blog: </b><a href=\"http://www.born2data.com/\" target=\"_blank\">born2data.com</a>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:center\">\n",
    "            <b>Personal Website: </b><a href=\"http://www.jonathandekhtiar.eu\" target=\"_blank\">jonathandekhtiar.eu</a>\n",
    "        </td>\n",
    "        <td style=\"text-align:center\">\n",
    "            <b>RSS Feed: </b><a href=\"https://www.feedcrunch.io/@dataradar/\" target=\"_blank\">FeedCrunch.io</a>\n",
    "        </td>\n",
    "        <td style=\"text-align:center\">\n",
    "            <b>LinkedIn: </b><a href=\"https://fr.linkedin.com/in/jonathandekhtiar\" target=\"_blank\">JonathanDEKHTIAR</a>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "## Objectives\n",
    "\n",
    "This notebook aims to preprocess and prepare the dataset for later used during the training phase. \n",
    "\n",
    "There exists many methods to feed data into a Deep Learning with [Tensorflow](https://www.tensorflow.org/), the Python Library we have chosen to use for this study:\n",
    "\n",
    "1. **From Disk**: Data can be inputed into a model with the **feed_dict** argument when running a *training operation*. It would  definitely be possible, however this process can be slow if there are a lot of data to read simultaneously and could be too large to be held in the GPU Memory.\n",
    "<br><br>\n",
    "2. **From a CSV File**: This [type of file](https://en.wikipedia.org/wiki/Comma-separated_values) is not revelant when dealing with images.\n",
    "<br><br>\n",
    "3. **From a preprocessed binary file**: Tensorflow is able to save and recover data in a binary format called [TFRecords](https://www.tensorflow.org/api_guides/python/python_io#TFRecords_Format_Details). The data can be preprocessed beforehand and only the necessary data can be saved and read in real time during the training. This approach is the fatest and most memory-efficient when dealing with images.\n",
    "\n",
    "This notebook will focus on generating the necessary **TFRecord** files. Generating **TFRecords** is less intuitive than \n",
    "[HDF5](https://en.wikipedia.org/wiki/Hierarchical_Data_Format), used in other Deep Learning libraries such as [Keras](https://keras.io/). Using **TFRecords** will give you access to natively available tools, such as *Queue Runners*, *Coordinators*, *Supervisors*, *etc.*, to design [data pipelines](https://www.tensorflow.org/programmers_guide/reading_data) and process the images in a batch fashion.\n",
    "\n",
    "This notebook will use [Tensorflow-Slim](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim) to ease the understanding and reduce the code complexity.\n",
    "\n",
    "As we aim to to later re-train a CNN Model\n",
    "\n",
    "This will be used later to retrain an CNN model: [Inception-V4](https://arxiv.org/abs/1602.07261) model developed by Szegedy et al. The model has been Pre-Trained with the [ImageNet](http://www.image-net.org/) dataset allowing a much more accurate result due to the large number of data avaiable in this dataset. We call this kind of process: \"*Transfer Learning*\".\n",
    "\n",
    "---\n",
    "\n",
    "As reminder before starting, the data have already been preprocessed in the first Notebook: **[DICE - Notebook 1 - Dataset Augmentation](https://github.com/DEKHTIARJonathan/DICE-DMU_Imagery_Classification_Engine/blob/master/DICE%20-%20Notebook%201%20-%20Dataset%20Augmentation.ipynb)**\n",
    "\n",
    "The preprocessed data all have been saved as **JPEG images** and thus we will only focus on these data.\n",
    "\n",
    "## 1. Notebook Initialisation\n",
    "\n",
    "### 1.1. Load the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, random\n",
    "import tensorflow as tf\n",
    "from dataset_utils import _dataset_exists, _get_filenames_and_classes, write_label_file, _convert_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1.2 Initialise global variables and application Flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flags = tf.app.flags\n",
    "\n",
    "#State your dataset directory\n",
    "flags.DEFINE_string('dataset_dir', 'data_augmented/total', 'String: Your dataset directory')\n",
    "\n",
    "#Output filename for the naming the TFRecord file\n",
    "flags.DEFINE_string('output_dir', 'data_prepared/', 'String: The output filename to name your TFRecord file')\n",
    "\n",
    "# Proportion of dataset to be used for evaluation: 0.3 => 70% Training & 30% Validation\n",
    "flags.DEFINE_float('validation_size', 0.3, 'Float: The proportion of examples in the dataset to be used for validation')\n",
    "\n",
    "# The number of shards to split the dataset into.\n",
    "flags.DEFINE_integer('num_shards', 2, 'Int: Number of shards to split the TFRecord files into')\n",
    "\n",
    "# Seed for repeatability.\n",
    "flags.DEFINE_integer('random_seed', 666, 'Int: Random seed to use for repeatability.')\n",
    "\n",
    "#Output filename for the naming the TFRecord file\n",
    "flags.DEFINE_string('tfrecord_filename', 'dmunet_dataset', 'String: The output filename to name your TFRecord file')\n",
    "\n",
    "FLAGS = flags.FLAGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Create the output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(FLAGS.output_dir):\n",
    "    os.makedirs(FLAGS.output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "photo_filenames, class_names = _get_filenames_and_classes(FLAGS.dataset_dir)  \n",
    "class_names_to_ids = dict(zip(class_names, range(len(class_names))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Performing the train/val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Find the number of validation examples we need\n",
    "num_validation = int(FLAGS.validation_size * len(photo_filenames))\n",
    "\n",
    "# Divide the training datasets into train and test:\n",
    "random.seed(FLAGS.random_seed)\n",
    "random.shuffle(photo_filenames)\n",
    "training_filenames = photo_filenames[num_validation:]\n",
    "validation_filenames = photo_filenames[:num_validation]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Converting the datasets into TFRecords\n",
    "\n",
    "### 4.1. Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing TFRecord File: data_prepared/dmunet_dataset_train_00001-of-00002.tfrecord\n",
      "Shard Size 39864\n",
      "\n",
      "Converting image 1000/79726 - shard 1\n",
      "Converting image 2000/79726 - shard 1\n",
      "Converting image 3000/79726 - shard 1\n",
      "Converting image 4000/79726 - shard 1\n",
      "Converting image 5000/79726 - shard 1\n",
      "Converting image 6000/79726 - shard 1\n",
      "Converting image 7000/79726 - shard 1\n",
      "Converting image 8000/79726 - shard 1\n",
      "Converting image 9000/79726 - shard 1\n",
      "Converting image 10000/79726 - shard 1\n",
      "Converting image 11000/79726 - shard 1\n",
      "Converting image 12000/79726 - shard 1\n",
      "Converting image 13000/79726 - shard 1\n",
      "Converting image 14000/79726 - shard 1\n",
      "Converting image 15000/79726 - shard 1\n",
      "Converting image 16000/79726 - shard 1\n",
      "Converting image 17000/79726 - shard 1\n",
      "Converting image 18000/79726 - shard 1\n",
      "Converting image 19000/79726 - shard 1\n",
      "Converting image 20000/79726 - shard 1\n",
      "Converting image 21000/79726 - shard 1\n",
      "Converting image 22000/79726 - shard 1\n",
      "Converting image 23000/79726 - shard 1\n",
      "Converting image 24000/79726 - shard 1\n",
      "Converting image 25000/79726 - shard 1\n",
      "Converting image 26000/79726 - shard 1\n",
      "Converting image 27000/79726 - shard 1\n",
      "Converting image 28000/79726 - shard 1\n",
      "Converting image 29000/79726 - shard 1\n",
      "Converting image 30000/79726 - shard 1\n",
      "Converting image 31000/79726 - shard 1\n",
      "Converting image 32000/79726 - shard 1\n",
      "Converting image 33000/79726 - shard 1\n",
      "Converting image 34000/79726 - shard 1\n",
      "Converting image 35000/79726 - shard 1\n",
      "Converting image 36000/79726 - shard 1\n",
      "Converting image 37000/79726 - shard 1\n",
      "Converting image 38000/79726 - shard 1\n",
      "Converting image 39000/79726 - shard 1\n",
      "\n",
      "#######################\n",
      "\n",
      "Processing TFRecord File: data_prepared/dmunet_dataset_train_00002-of-00002.tfrecord\n",
      "Shard Size 39864\n",
      "\n",
      "Converting image 40000/79726 - shard 2\n",
      "Converting image 41000/79726 - shard 2\n",
      "Converting image 42000/79726 - shard 2\n",
      "Converting image 43000/79726 - shard 2\n",
      "Converting image 44000/79726 - shard 2\n",
      "Converting image 45000/79726 - shard 2\n",
      "Converting image 46000/79726 - shard 2\n",
      "Converting image 47000/79726 - shard 2\n",
      "Converting image 48000/79726 - shard 2\n",
      "Converting image 49000/79726 - shard 2\n",
      "Converting image 50000/79726 - shard 2\n",
      "Converting image 51000/79726 - shard 2\n",
      "Converting image 52000/79726 - shard 2\n",
      "Converting image 53000/79726 - shard 2\n",
      "Converting image 54000/79726 - shard 2\n",
      "Converting image 55000/79726 - shard 2\n",
      "Converting image 56000/79726 - shard 2\n",
      "Converting image 57000/79726 - shard 2\n",
      "Converting image 58000/79726 - shard 2\n",
      "Converting image 59000/79726 - shard 2\n",
      "Converting image 60000/79726 - shard 2\n",
      "Converting image 61000/79726 - shard 2\n",
      "Converting image 62000/79726 - shard 2\n",
      "Converting image 63000/79726 - shard 2\n",
      "Converting image 64000/79726 - shard 2\n",
      "Converting image 65000/79726 - shard 2\n",
      "Converting image 66000/79726 - shard 2\n",
      "Converting image 67000/79726 - shard 2\n",
      "Converting image 68000/79726 - shard 2\n",
      "Converting image 69000/79726 - shard 2\n",
      "Converting image 70000/79726 - shard 2\n",
      "Converting image 71000/79726 - shard 2\n",
      "Converting image 72000/79726 - shard 2\n",
      "Converting image 73000/79726 - shard 2\n",
      "Converting image 74000/79726 - shard 2\n",
      "Converting image 75000/79726 - shard 2\n",
      "Converting image 76000/79726 - shard 2\n",
      "Converting image 77000/79726 - shard 2\n",
      "Converting image 78000/79726 - shard 2\n",
      "Converting image 79000/79726 - shard 2\n",
      "\n",
      "#######################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_convert_dataset(\n",
    "    split_name             = 'train', \n",
    "    filenames              = training_filenames, \n",
    "    class_names_to_ids     = class_names_to_ids,\n",
    "    dataset_dir            = FLAGS.dataset_dir,\n",
    "    output_dir             = FLAGS.output_dir,\n",
    "    tfrecord_filename      = FLAGS.tfrecord_filename,\n",
    "    _NUM_SHARDS            = FLAGS.num_shards\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing TFRecord File: data_prepared/dmunet_dataset_validation_00001-of-00002.tfrecord\n",
      "Shard Size 17085\n",
      "\n",
      "Converting image 1000/34168 - shard 1\n",
      "Converting image 2000/34168 - shard 1\n",
      "Converting image 3000/34168 - shard 1\n",
      "Converting image 4000/34168 - shard 1\n",
      "Converting image 5000/34168 - shard 1\n",
      "Converting image 6000/34168 - shard 1\n",
      "Converting image 7000/34168 - shard 1\n",
      "Converting image 8000/34168 - shard 1\n",
      "Converting image 9000/34168 - shard 1\n",
      "Converting image 10000/34168 - shard 1\n",
      "Converting image 11000/34168 - shard 1\n",
      "Converting image 12000/34168 - shard 1\n",
      "Converting image 13000/34168 - shard 1\n",
      "Converting image 14000/34168 - shard 1\n",
      "Converting image 15000/34168 - shard 1\n",
      "Converting image 16000/34168 - shard 1\n",
      "Converting image 17000/34168 - shard 1\n",
      "\n",
      "#######################\n",
      "\n",
      "Processing TFRecord File: data_prepared/dmunet_dataset_validation_00002-of-00002.tfrecord\n",
      "Shard Size 17085\n",
      "\n",
      "Converting image 18000/34168 - shard 2\n",
      "Converting image 19000/34168 - shard 2\n",
      "Converting image 20000/34168 - shard 2\n",
      "Converting image 21000/34168 - shard 2\n",
      "Converting image 22000/34168 - shard 2\n",
      "Converting image 23000/34168 - shard 2\n",
      "Converting image 24000/34168 - shard 2\n",
      "Converting image 25000/34168 - shard 2\n",
      "Converting image 26000/34168 - shard 2\n",
      "Converting image 27000/34168 - shard 2\n",
      "Converting image 28000/34168 - shard 2\n",
      "Converting image 29000/34168 - shard 2\n",
      "Converting image 30000/34168 - shard 2\n",
      "Converting image 31000/34168 - shard 2\n",
      "Converting image 32000/34168 - shard 2\n",
      "Converting image 33000/34168 - shard 2\n",
      "Converting image 34000/34168 - shard 2\n",
      "\n",
      "#######################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_convert_dataset(\n",
    "    split_name             = 'validation', \n",
    "    filenames              = validation_filenames, \n",
    "    class_names_to_ids     = class_names_to_ids,\n",
    "    dataset_dir            = FLAGS.dataset_dir,\n",
    "    output_dir             = FLAGS.output_dir,\n",
    "    tfrecord_filename      = FLAGS.tfrecord_filename,\n",
    "    _NUM_SHARDS            = FLAGS.num_shards\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Finally, we write a labels file that will be useful as a reference later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_to_class_names = dict(zip(range(len(class_names)), class_names))\n",
    "write_label_file(labels_to_class_names, FLAGS.output_dir, filename=\"labels.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

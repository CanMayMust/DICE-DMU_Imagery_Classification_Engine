{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DICE - Notebook 2 - Dataset Preparation\n",
    "\n",
    "<br/>\n",
    "\n",
    "```\n",
    "*************************************************************************\n",
    "**\n",
    "** 2017 Mai 23\n",
    "**\n",
    "** In place of a legal notice, here is a blessing:\n",
    "**\n",
    "**    May you do good and not evil.\n",
    "**    May you find forgiveness for yourself and forgive others.\n",
    "**    May you share freely, never taking more than you give.\n",
    "**\n",
    "*************************************************************************\n",
    "```\n",
    "\n",
    "<table style=\"width:100%; font-size:14px; margin: 20px 0;\">\n",
    "    <tr>\n",
    "        <td style=\"text-align:center\">\n",
    "            <b>Contact: </b><a href=\"mailto:contact@jonathandekhtiar.eu\" target=\"_blank\">contact@jonathandekhtiar.eu</a>\n",
    "        </td>\n",
    "        <td style=\"text-align:center\">\n",
    "            <b>Twitter: </b><a href=\"https://twitter.com/born2data\" target=\"_blank\">@born2data</a>\n",
    "        </td>\n",
    "        <td style=\"text-align:center\">\n",
    "            <b>Tech. Blog: </b><a href=\"http://www.born2data.com/\" target=\"_blank\">born2data.com</a>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:center\">\n",
    "            <b>Personal Website: </b><a href=\"http://www.jonathandekhtiar.eu\" target=\"_blank\">jonathandekhtiar.eu</a>\n",
    "        </td>\n",
    "        <td style=\"text-align:center\">\n",
    "            <b>RSS Feed: </b><a href=\"https://www.feedcrunch.io/@dataradar/\" target=\"_blank\">FeedCrunch.io</a>\n",
    "        </td>\n",
    "        <td style=\"text-align:center\">\n",
    "            <b>LinkedIn: </b><a href=\"https://fr.linkedin.com/in/jonathandekhtiar\" target=\"_blank\">JonathanDEKHTIAR</a>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "## Objectives\n",
    "\n",
    "This notebook aims to preprocess and prepare the dataset for later used during the training phase. \n",
    "\n",
    "There exists many methods to feed data into a Deep Learning with [Tensorflow](https://www.tensorflow.org/), the Python Library we have chosen to use for this study:\n",
    "\n",
    "1. **From Disk**: Data can be inputed into a model with the **feed_dict** argument when running a *training operation*. It would  definitely be possible, however this process can be slow if there are a lot of data to read simultaneously and could be too large to be held in the GPU Memory.\n",
    "<br><br>\n",
    "2. **From a CSV File**: This [type of file](https://en.wikipedia.org/wiki/Comma-separated_values) is not revelant when dealing with images.\n",
    "<br><br>\n",
    "3. **From a preprocessed binary file**: Tensorflow is able to save and recover data in a binary format called [TFRecords](https://www.tensorflow.org/api_guides/python/python_io#TFRecords_Format_Details). The data can be preprocessed beforehand and only the necessary data can be saved and read in real time during the training. This approach is the fatest and most memory-efficient when dealing with images.\n",
    "\n",
    "This notebook will focus on generating the necessary **TFRecord** files. Generating **TFRecords** is less intuitive than \n",
    "[HDF5](https://en.wikipedia.org/wiki/Hierarchical_Data_Format), used in other Deep Learning libraries such as [Keras](https://keras.io/). Using **TFRecords** will give you access to natively available tools, such as *Queue Runners*, *Coordinators*, *Supervisors*, *etc.*, to design [data pipelines](https://www.tensorflow.org/programmers_guide/reading_data) and process the images in a batch fashion.\n",
    "\n",
    "This notebook will use [Tensorflow-Slim](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim) to ease the understanding and reduce the code complexity.\n",
    "\n",
    "As we aim to to later re-train a CNN Model\n",
    "\n",
    "This will be used later to retrain an CNN model: [Inception-V4](https://arxiv.org/abs/1602.07261) model developed by Szegedy et al. The model has been Pre-Trained with the [ImageNet](http://www.image-net.org/) dataset allowing a much more accurate result due to the large number of data avaiable in this dataset. We call this kind of process: \"*Transfer Learning*\".\n",
    "\n",
    "\n",
    "This notebook will also randomly split the available data into two sets of data: [Training and Validation sets](https://stats.stackexchange.com/questions/19048/what-is-the-difference-between-test-set-and-validation-set). This process aims to reduce the [overfit](http://scikit-learn.org/stable/auto_examples/model_selection/plot_underfitting_overfitting.html) of the model and thus improving its accuracy on previously unseen data. \n",
    "\n",
    "In this study the selection ratio has been chosen as followed:\n",
    "- *training set:* 60%\n",
    "- *validation set:* 40%.\n",
    "\n",
    "---\n",
    "\n",
    "As reminder before starting, the data have already been preprocessed (resized, augmented, etc.) in the first Notebook: **[DICE - Notebook 1 - Dataset Augmentation](https://github.com/DEKHTIARJonathan/DICE-DMU_Imagery_Classification_Engine/blob/master/DICE%20-%20Notebook%201%20-%20Dataset%20Augmentation.ipynb)**\n",
    "\n",
    "The preprocessed data all have been saved as **JPEG images** and thus we will only focus on these data.\n",
    "\n",
    "## 1. Notebook Initialisation\n",
    "\n",
    "### 1.1. Load the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'inception_utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-7e6218b68aa5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtest_files\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimagenet\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtest_files\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minception_v1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minception_v1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minception_v1_arg_scope\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minception_v1_base\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtest_files\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minception_preprocessing\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Git Projects\\DICE-DMU_Imagery_Classification_Engine\\test_files\\nets\\inception_v1.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtest_files\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minception_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mslim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mslim\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'inception_utils'"
     ]
    }
   ],
   "source": [
    "import os, sys, io\n",
    "import urllib.request, urllib.error, urllib.parse\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from test_files.datasets import imagenet\n",
    "from test_files.nets.inception_v1 import inception_v1, inception_v1_arg_scope, inception_v1_base\n",
    "from test_files.preprocessing import inception_preprocessing\n",
    "\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "image_size = inception_v1.default_image_size\n",
    "\n",
    "image_url = 'https://upload.wikimedia.org/wikipedia/commons/7/70/EnglishCockerSpaniel_simon.jpg'\n",
    "#image_url = 'http://www.waggfoods.com/assets/wagg/img/page/home/dogs.png'\n",
    "image_data = urllib.request.urlopen(image_url)\n",
    "image_string = image_data.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(io.BytesIO(image_string))\n",
    "plt.imshow(np.asarray(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ext = image_url.split(\".\")[-1:][0].lower()\n",
    "\n",
    "jpeg_ext_list = [\"jpg\", \"jpeg\"]\n",
    "\n",
    "file_cond = tf.equal(image_ext, jpeg_ext_list)\n",
    "file_cond = tf.count_nonzero(file_cond)\n",
    "file_cond = tf.equal(file_cond, 1) ## 1 => JPEG EXTENSION, 0 => PNG EXTENSION\n",
    "        \n",
    "image = tf.cond(\n",
    "    file_cond, \n",
    "    lambda: tf.image.decode_jpeg(image_string, channels=3), \n",
    "    lambda: tf.image.decode_png(image_string, channels=3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "processed_image   = inception_preprocessing.preprocess_image(image, image_size, image_size, is_training=False)\n",
    "processed_images  = tf.expand_dims(processed_image, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model, use the default arg scope to configure the batch norm parameters.\n",
    "with slim.arg_scope(inception_v1_arg_scope()):\n",
    "    logits, _ = inception_v1(processed_images, num_classes=1001, is_training=False)\n",
    "    \n",
    "probabilities = tf.nn.softmax(logits)\n",
    "checkpoints_dir='test_files' \n",
    "\n",
    "init_fn = slim.assign_from_checkpoint_fn(\n",
    "    os.path.join(checkpoints_dir, 'models/inception_v1.ckpt'),\n",
    "    slim.get_variables_to_restore()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    init_fn(sess)\n",
    "    np_image, probabilities = sess.run([image, probabilities])\n",
    "    probabilities = probabilities[0, 0:]\n",
    "    sorted_inds = [i[0] for i in sorted(enumerate(-probabilities), key=lambda x:x[1])]\n",
    "    \n",
    "    names = imagenet.create_readable_names_for_imagenet_labels()\n",
    "    result_text=''\n",
    "\n",
    "    print()\n",
    "\n",
    "    for i in range(5):\n",
    "        index = sorted_inds[i]\n",
    "        print(('Probability %0.2f%% => [%s]' % (100*probabilities[index], names[index])))\n",
    "\n",
    "    result_text+=str(names[sorted_inds[0]])+'=>'+str( \"{0:.2f}\".format(100*probabilities[sorted_inds[0]]))+'%\\n'\n",
    "\n",
    "    plt.figure(num=1,figsize=(8, 6), dpi=80)\n",
    "    plt.imshow(np_image.astype(np.uint8))\n",
    "    plt.text(150,100,result_text,horizontalalignment='center', verticalalignment='center',fontsize=21,color='blue')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
